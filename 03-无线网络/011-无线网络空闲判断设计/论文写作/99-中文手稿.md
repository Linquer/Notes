

#### 标题
"Cognitive Channel Access Strategy Selection: An LLM-Agent Approach for Dynamic Real-time Networks"
（认知信道接入策略选择：面向动态实时网络的LLM代理方法）
LLM-Agent Driven Cognitive Channel Access Strategy for Dynamic Real-time Networks
LLM-Agent Driven Hybrid Cognitive Channel Access Strategy for Dynamic Real-time Networks

#### 摘要
无线网络中多节点信道接入的动态管理是一个极具挑战性的研究问题，尤其在节点流量强度随机变化的完全分布式网络中，现有方法难以满足多变环境的多样化需求。此前的分布式信道接入算法在局域网内部通常是单一的，所有节点采用相同算法获得同等接入能力，无法适应多节点实时动态变化的差异化需求。为此，本研究提出了一种专为多变实时环境设计的混合信道接入方法。设计了双均值混合密度网络（DM-MDN）对信道空闲时长进行动态预测，有效捕获信道当前负载强度，帮助节点决策是否发送数据包，从而实现智能化信道接入。DM-MDN能够应对信道空闲时长分布的多峰特性，提升预测的准确性和适应性。此外，考虑到不同节点对信道接入能力的不同需求，本研究设计了基于大语言模型智能体（LLM Agent）的资源分配框架，实现了CSMA/CA与基于预测的DM-MDN两种接入策略的混合管理。决策智能体负责实时调整节点接入策略，经验智能体则总结历史决策经验并辅助优化，形成了一个完整的混合信道接入管理系统。实验结果表明，本方法在提升网络性能、增强节点接入灵活性及优化分布式资源利用方面具有显著优势，为复杂无线网络的资源管理提供了新思路。

#### Introduction
无线网络作为现代通信基础设施的核心组成部分，在智能化时代的各类应用场景中扮演着至关重要的角色。当前，网络节点数量快速增长，节点间通信需求日益复杂多变。尤其在高密度部署场景下，有限的频谱资源如何被多节点高效共享成为一个关键挑战。信道接入作为无线通信的基础环节，其性能直接影响整个网络的吞吐量、延迟和丢包率等关键指标。

然而，在实际网络环境中，各节点的流量需求往往呈现出高度动态性和随机性，不同时段、不同位置的节点可能面临截然不同的通信需求[1,2,3]，这使得传统的单一策略的信道接入策略难以同时满足这些多样化需求，无法在快速变化的网络环境中做出合理的信道接入策略选择。因此，设计一种能够适应多变环境、满足差异化需求的动态信道接入管理机制具有重要的理论价值和实际应用意义。

在分布式无线网络信道接入领域，基于竞争的协议如CSMA/CA被广泛应用于IEEE 802.11等无线网络标准中。这类方法通过随机退避机制和碰撞检测实现多节点的分布式协调[###]，具有实现简单、无需中心控制的优势。然而，研究表明，CSMA/CA在高负载条件下由于频繁碰撞会导致严重的性能退化[###]。更重要的是，传统CSMA/CA在局域网内部通常对所有节点应用相同的参数设置，使得所有节点获得近似相等的信道接入机会，无法根据节点的不同需求提供差异化服务。虽然已有研究[###]提出通过动态调整竞争窗口大小等参数来优化性能，但这些改进大多针对平均性能优化，难以满足各节点实时动态变化的差异化需求。

此外，已有一些研究尝试通过预测信道状态来辅助接入决策。然而，这些方法大多采用单一分布模型或简单的神经网络结构，无法有效捕捉实际网络中信道空闲时长的多峰分布特性，预测精度有限，特别是在网络负载快速变化的场景下适应性不足。

为了满足网络中各节点的多样化需求，本研究设计了一种基于信道空闲时间预测的信道接入方法。该方法利用历史信道空闲时段数据来预测未来的信道可用窗口，以此辅助节点做数据包是否发送决策。实际网络环境具有高度的动态性和随机性，大量研究表明[###]网络数据的拥塞程度呈现明显的多峰分布特性。针对这一复杂特性，我们采用了双均值混合密度网络（DM-MDN）对信道的拥塞状态进行建模和预测。得益于混合密度网络在处理多峰分布数据上的优势，该模型能够有效捕捉信道当前的负载模式，从而实现更为准确的预测，使节点能够根据网络实时状况做出智能化的接入决策。

然而，基于信道空闲时间预测的信道接入方法允许节点在预测的信道可用窗口内直接发送数据包，省略了CSMA/CA协议中的间隔帧和二进制指数退避等等待机制。此方法虽提高了单个节点的信道接入效率，但随着局域网内采用该方法的节点数量增加，由于节点间缺乏协调机制，导致节点间竞争加剧，从而使网络整体性能下降。基于这一现象，本研究提出在同一局域网内，节点可以灵活采用两种接入算法：DM-MDN和CSMA/CA。

多协议网络环境中，需要一个高层次的"元算法"来动态决定特定场景下应采用的信道接入算法。现有的调度选择算法可分为两类：传统算法和数据驱动的算法。传统算法构建于预设规则、启发式方法或数学模型之上，如基于排队论的调度算法、优先级算法或负载均衡算法，这些方法依赖精确的数学建模和专家知识。数据驱动的算法则包括机器学习、深度学习或深度强化学习等方法，通过分析网络性能数据来优化算法选择策略。但是，无论传统算法还是数据驱动算法，大多数都未能充分利用历史信息构建有效的认知策略。当前算法通常仅关注瞬时网络状态或短期历史数据，缺乏对长期网络行为模式的理解和推断能力，难以深入把握网络环境的演变规律。这一局限性使现有调度算法在复杂多变的网络环境中难以实现真正智能化、前瞻性的算法选择决策。

开始写LLM Agent 结构 


#### Experiment Results
本章节将从预测模型的准确性验证与实际网络性能评估两个方面展开实验分析，随后对比不同LLM Agent方法的性能及其在资源占用方面的差异。本实验基于一个开源的IEEE 802.11g网络仿真平台展开，该平台由Micheletto等人开发[###]。在所有实验中，我们采用了统一的网络协议栈配置和仿真参数（包括802.11物理层速率、MAC层退避策略等），并通过调整负载规模和节点需求等变量，针对性地评估各方法在不同场景下的表现。

##### Experimental Setup
###### Simulation platform
在本研究中，我们构建的仿真环境基于IEEE 802.11g标准，采用2.4 GHz频段，传输速率为54 Mbit/s。MAC层参数中，竞争窗口设置为CW_MIN = 16和CW_MAX = 1024，同时规定MAC帧格式中包头最大长度为34B、数据载荷最大长度为2312B；在信号传播方面，则采用自由空间路径损耗（FSPL, Free Space Path Loss）模型来描述信号功率随距离的衰减情况，从而更真实地反映无线传输的物理特性。
###### 模型结构
在预测实验中，采用了基于70000数据包仿真后获得的信道空闲数据作为训练样本，对各预测模型进行训练。所提出的DM-MDN模型由三层神经网络构成主干，后续的四个分支输出模型结构均为单层神经网络，并全部使用ReLU作为激活函数。为了评估性能，我们还选取了两种对比模型：基于GRU的模型利用PyTorch标准GRU结构堆叠4层，后接两层神经网络作为输出层；而基于Transformer的模型在编码器部分采用PyTorch提供的TransformerEncoderLayer，并在输出层设置单层神经网络。
###### 网络拓扑和流量模型
我们构建了由单个接入点(AP)和多个客户端节点组成的星型网络拓扑，节点的数量取决于当前的实验场景，数量为3-7个。采用单跳传输方式进行数据包传输。实验中各节点均直接与AP相连，无需中继节点。
为模拟真实环境中的动态流量特性，我们为每个节点设计了基于三元组参数的随机流量模型。该模型由offset(起始偏移时间，0-3000微秒)、packet_interval(数据包到达间隔，500-2500微秒)及arrive_probability(数据包到达概率，0.7-0.99)组成，这些参数均通过均匀分布的随机算法生成。

##### 预测实验结果
在预测信道空闲长度的任务中，主要对比的基线模型为GRU和Transformer，这两个对比模型的具体结构在 模型结构 这一节中已经详细介绍。
###### 预测精度结果
表 1 展示了 DM-MDN 和 MDN 相较于基线模型在测试数据集上的预测绝对误差对比。测试数据集涵盖了不同网络负载情况下的仿真数据，且网络负载的变化是完全随机的。需要特别说明的是，在该测试中，DM-MDN 的最终预测值 final_mu 计算方式为 mu + mu_bias，其原因在于本实验旨在验证混合密度网络（MDN）能否准确预测当前网络的负载情况。而 mu_bias 的去除通常是为了避免预测值偏大，从而提升模型的在网络场景下的性能。
由于网络环境具有高度随机性，四种方法的预测精度均相对较低。然而，混合密度网络能够有效捕捉训练数据中的多峰分布特性，使其能够更精准地判断网络的当前负载情况，并基于负载状态进行合理预测。从表 1 可见，在预测精度方面，混合密度网络较基线模型 GRU 和 Transformer 分别提升了约 xx% 和 xx%，显示出其在复杂网络环境下的优越性。

###### 预测模型在仿真中的结果
我们在三种不同负载场景下，对比了DM-MDN与基线方法在实际网络仿真中的性能表现。表1、表2和表3分别展示了平均数据包时延、丢包率和系统吞吐量的对比结果。

xxxx（具体表现）

在低负载场景下，我们发现基于GRU和Transformer的预测方法，在仿真中的结果和DM-MDN相比出现较大的差异。通过分析在仿真中GRU和Transformer的预测值发现，它们无法捕捉到当前是低负载的场景，其输出的预测值依然集中在高负载场景下的信道空闲情况。这导致了GRU和Transformer的预测值较小，而当节点数据包到达时，数据包到达的时隙很难落在预测的信道空闲时隙，这导致了节点数据包经常错过了发送时机。

##### LLM-Agent 实验结果
我们对比了本文提出的LLM Agent资源分配框架与Reflexion、Strategy以及传统贪心算法在四种大语言模型上的性能表现以及它们的资源占用情况。
###### 动态场景
为全面评估本文提出的LLM Agent资源分配框架性能，我们构建了一个具有动态优先级特性的无线网络实验场景。该场景由五个普通节点和一个接入点(AP)组成，网络中每个节点的数据包优先级均呈现动态变化特性。数据包优先级分为三个等级：优先级1（最低）、优先级2（中等）和优先级3（最高），其中优先级1的数据包不受传输时限限制，而优先级2和优先级3的数据包则分别设置了1200微秒和900微秒的截止时限(deadline)约束。
在实验过程中，每个节点的数据包优先级由均匀分布的随机算法确定，模拟实际网络中业务需求的变化特性。当节点数据包优先级发生变化后，系统会将网络中所有节点的最新优先级信息提交至资源分配算法。该算法根据当前网络状态和各节点需求，决定每个节点应采用的信道接入策略（传统CSMA/CA或基于DM-MDN的预测方法），并为选择DM-MDN策略的节点确定最优分位数参数，从而实现对异构节点的差异化资源分配与管理。
考虑到本研究主要针对动态实时网络环境，我们将高优先级节点的丢包率作为主要评估指标。在具有严格时限要求的场景中，数据包的可靠传输对保障服务质量至关重要，特别是对优先级较高的业务而言，丢包率能够直接反映算法在异构资源需求管理方面的能力。基于这一考虑，我们在LLM Agent的设计中将降低高优先级数据包的丢包率设定为优化的核心目标，以验证所提出框架在动态环境下的适应性和决策能力。
###### LLM-Agent 实验结果分析

###### 算法资源开销分析
