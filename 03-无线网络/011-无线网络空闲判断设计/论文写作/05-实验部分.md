#### Experiment Results
本章节将评估DM-MDN预测的准确性验证和其实际性能，其次，对比不同LLM Agents方法的性能及其在资源占用方面的差异。本实验基于一个开源的IEEE 802.11g网络仿真平台展开，该平台由Micheletto等人开发。

##### Experimental Setup
###### Simulation platform
在本研究中，我们构建的仿真环境基于IEEE 802.11g标准，采用2.4 GHz频段，传输速率为54 Mbit/s。MAC层参数中，竞争窗口设置为CW_MIN = 16和CW_MAX = 1024，同时规定MAC帧格式中包头最大长度为34B、数据载荷最大长度为2312B；在信号传播方面，则采用自由空间路径损耗（FSPL, Free Space Path Loss）模型来描述信号功率随距离的衰减情况，从而更真实地反映无线传输的物理特性。
我们构建了一个星型网络拓扑，由单个接入点和3至7个客户端节点组成，节点数量根据实验场景需求进行调整。在Dynamic Traffic Model 章节中提到的三元组参数流量模型。以下为三个参数均匀分布采样的范围：offset(0,3000us)：起始偏移时间，interval(500,2500us):数据包到达间隔，prob(0.7,0.99):数据包到达概率。
###### 模型结构
预测实验采用了基于70000个数据包仿真获取的信道空闲数据作为训练样本。DM-MDN模型由三层神经网络构成主干，配合四个单层神经网络分支作为输出结构，全部使用ReLU激活函数。为进行性能评估，我们选择了两种对比模型：一种基于GRU，由PyTorch标准GRU结构堆叠4层并接两层神经网络输出层；另一种基于Transformer，其编码器采用PyTorch提供的TransformerEncoderLayer堆叠2层，输出层为单层神经网络。


##### 预测实验结果
###### 预测精度结果
在预测信道空闲长度的任务中，我们主要将 DM-MDN 与 GRU 和 Transformer 基线模型进行了对比。表 1 展示了 DM-MDN 和 MDN 在随机采样下相较于基线模型在测试数据集上的预测Mean Absolute Error(MAE)对比结果。测试数据集包含了不同网络负载条件下的仿真数据，且网络负载变化是完全随机特性。在本实验中，DM-MDN 的均值计算公式为 μ = μ_base + μ_offset，这主要是因为我们旨在验证 DM-MDN 能否准确感知并预测当前网络的负载状态。
由于网络环境的高度随机性，所有四种方法的预测精度整体偏低。然而，混合密度网络能够有效捕捉训练数据中的多峰分布特征，从而更准确地识别网络的当前负载情况，并基于负载状态在合理范围内作出预测。从表 1 数据可以看出，DM-MDN 在预测精度方面较基线模型 GRU 和 Transformer 分别提升了约 xx% 和 xx%，展现了其在复杂网络环境下的优越性能。此外，DM-MDN 与 MDN 在预测精度上差异极小，这证明了将均值进行结构化分解并不会损害模型的整体预测能力。

###### 预测模型在仿真中的结果
我们在三种不同负载场景下，对比了DM-MDN与基线方法在实际网络仿真中的性能表现。表2展示了在三种负载情况下，数据包平均时延、丢包率和吞吐量的对比结果。在该实验中，采用预测算法的节点数据包优先级为3，数据包deadline为900微秒。其他节点数据包优先级为1不做deadline限制，采用CSMA/CA接入算法。三种负载情况对于的发送数据包节点个数为：3(Low)、5(Mid)、7(High)。

xxxx（具体表现）

在中高网络负载情况下，DM-MDN在核心指标丢包率上明显优于基线模型，并且领先于MDN。这主要得益于DM-MDN在复杂网络环境中的预测更加稳定，不容易出现“过度乐观”的情况。然而，在低负载下，尽管DM-MDN的丢包率优于基线模型，但仍逊色于MDN。通过分析网络数据发现，低负载时信道空闲时隙较长，而DM-MDN的决策较为保守，导致节点容易错过最佳的发送时机。
在低负载场景中，GRU和Transformer的预测方法与DM-MDN相比存在较大差异。分析结果表明，这两种方法未能准确识别低负载环境，预测值仍集中在高负载时的信道空闲情况。因此，它们的预测值较小，节点数据包难以在预测的空闲时隙内到达，从而错过发送时机。

###### 不同分位数下的算法表现
对于DM-MDN算法而言，不同的分位数参数代表了不同的信道接入能力。理论上，分位数越高，信道接入能力相对越强。然而，由于网络场景的多样性，最优分位数参数会随网络环境变化而不同。
图3展示了在三种不同场景下，采用DM-MDN节点在不同分位数下的数据包丢包率。实验环境包含6个节点，其中图3的(a)、(b)、(c)子图分别对应1个、2个、3个节点采用DM-MDN作为信道接入算法的情况（采用DM-MDN算法的节点数据包优先级均为3）。图3(d)则综合展示了这三种场景下DM-MDN算法的平均丢包率，以及与采用CSMA/CA且优先级为3的节点丢包率进行了对比。
从图3可以看出，DM-MDN算法的丢包率总体上随着分位数的增加而减少。然而，最优分位数在不同场景下各不相同，且并非都是最大值0.9。因此，确定特定场景下的最优分位数，需要综合考虑历史信息和当前网络环境特征。值得注意的是，如图3(d)所示，虽然随着采用DM-MDN的节点数量增多，丢包率也随之增加，但无论采用何种分位数，DM-MDN算法的丢包率整体上都优于CSMA/CA算法的节点。


##### LLM-Agent 实验结果
###### 场景设计
为全面评估NetCogAgents资源分配框架性能，设计了一个具有动态优先级特性的无线网络实验场景。该场景包含5个节点和1个接入点(AP)，每个节点的数据包优先级动态变化。其中，优先级1的数据包无传输时限限制，而优先级2和优先级3的数据包分别设有1200微秒和900微秒的截止时限。在时限要求严格的场景中，数据包的可靠传输至关重要，本研究聚焦动态实时网络环境，采用高优先级节点的丢包率作为主要评估指标。
实验中，部分节点的数据包优先级通过均匀分布的随机算法模拟网络业务需求变化。节点优先级变化时，系统会更新并提交优先级信息至资源分配算法，后者根据网络状态和节点需求选择合适的信道接入策略（CSMA/CA或DM-MDN），并为DM-MDN设置分位数参数，实现差异化资源分配。

###### LLM-Agent 实验结果分析
我们对NetCogAgents与Reflexion、StrategyLLM以及传统贪心+自适应算法在四种大型语言模型上的性能进行了全面比较。为了确保实验结果的可靠性，在每种LLMs进行了三轮完全随机的节点动态需求变化测试。表3展示了这四种方法在实验中所获得的平均数据包丢包率。值得注意的是，在这十二次实验中，每轮节点变化序列均不相同。实验结果表明，NetCogAgents在整体平均丢包率方面显著优于其他方法，这主要归功于其高效的经验组织方式和反思机制所实现的快速适应能力。
从实验数据来看，Reflexion的性能波动最为显著，其结果分布范围较广，既有优异表现也有明显劣势。这种不稳定性主要源于其保留所有决策轨迹的机制，随着系统持续运行，决策依据逐渐变得冗余复杂，导致其决策模块难以从大量历史轨迹中提取有效信息。
StrategyLLM展现出较为稳定的性能，但其决策质量在很大程度上取决于初始生成策略的质量。在正确策略指导下，StrategyLLM能够接近最优决策；然而，若初始策略不当，其决策效果则显著降低。此外，StrategyLLM的策略更新机制较为缓慢，难以有效应对快速变化的动态场景需求。
传统方法主要采用贪心与自适应相结合的策略。具体而言，对高优先级节点应用DM-MDN方法，而低优先级节点则采用CSMA/CA方法。DM-MDN的分位数初始值设定为0.5，并通过自适应策略根据每次的丢包率结果以0.1为步长进行上下调整，以实现性能优化。这种贪心机制能让该方法在初期取得相对好的成绩，但是其策略调整较为机械，后续策略调整的速度明显不如其他方法。

###### 内存资源开销分析
考虑到网络管理设备通常具有有限的存储资源，同时，过长的决策历史输入也可能影响大型语言模型的推理效率与决策质量。因此，在设计NetCogAgents结构的时候就考虑到，需要在保证决策效果的前提下，尽可能地减少决策历史所占用的内存。图X展示了NetCogAgents、Reflexion和StrategyLLM在四种大语言模型中，在网络决策的过程中它们占用内存的情况。

在此需要说明，图中的"Memory Usage"并非指大语言模型输出的实际内存占用情况。由于大语言模型的输出长度在不同的网络场景下会发生变化，即使在相同语境下也可能存在显著差异。因此，我们采用了更便于量化的统一计量方式：对于NetCogAgents，每条经验记录计为1单位内存占用；对于Reflexion，每次历史决策轨迹及其对应的反思经验共同计为1单位内存占用；对于StrategyLLM，每条初始生成的策略计为1单位内存占用。

从图X中可以明显观察到Reflexion随着决策轮次增加而内存占用持续上升，这是由于其每轮决策都会保留完整的轨迹并生成新的反思内容。相比之下，StrategyLLM仅在系统初始化时生成预设的M条策略，后续若有策略更新也会直接覆盖原有策略，因此其内存占用始终保持稳定。NetCogAgents的内存使用则呈现出波动但整体较低的趋势，这主要得益于反思智能体持续优化并精简其经验区内容。此外，经验智能体在面对相同场景时通常不会生成新的决策内容，除非决策智能体更新了策略并取得更优的结果。
