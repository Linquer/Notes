#### Experiment Results
本章节将评估DM-MDN预测的准确性验证和其实际性能，其次，对比不同LLM Agents方法的性能及其在资源占用方面的差异。本实验基于一个开源的IEEE 802.11g网络仿真平台展开，该平台由Micheletto等人开发。

##### Experimental Setup
###### Simulation platform
在本研究中，我们构建的仿真环境基于IEEE 802.11g标准，采用2.4 GHz频段，传输速率为54 Mbit/s。MAC层参数中，竞争窗口设置为CW_MIN = 16和CW_MAX = 1024，同时规定MAC帧格式中包头最大长度为34B、数据载荷最大长度为2312B；在信号传播方面，则采用自由空间路径损耗（FSPL, Free Space Path Loss）模型来描述信号功率随距离的衰减情况，从而更真实地反映无线传输的物理特性。
我们构建了一个星型网络拓扑，由单个接入点和3至7个客户端节点组成，节点数量根据实验场景需求进行调整。在Dynamic Traffic Model 章节中提到的三元组参数流量模型。以下为三个参数均匀分布采样的范围：offset(0,3000us)：起始偏移时间，interval(500,2500us):数据包到达间隔，prob(0.7,0.99):数据包到达概率。
###### 模型结构
预测实验采用了基于70000个数据包仿真获取的信道空闲数据作为训练样本。DM-MDN模型由三层神经网络构成主干，配合四个单层神经网络分支作为输出结构，全部使用ReLU激活函数。为进行性能评估，我们选择了两种对比模型：一种基于GRU，由PyTorch标准GRU结构堆叠4层并接两层神经网络输出层；另一种基于Transformer，其编码器采用PyTorch提供的TransformerEncoderLayer堆叠2层，输出层为单层神经网络。


##### 预测实验结果
###### 预测精度结果
在预测信道空闲长度的任务中，我们主要将 DM-MDN 与 GRU 和 Transformer 基线模型进行了对比。表 1 展示了 DM-MDN 和 MDN 在随机采样下相较于基线模型在测试数据集上的预测Mean Absolute Error(MAE)对比结果。测试数据集包含了不同网络负载条件下的仿真数据，且网络负载变化是完全随机特性。在本实验中，DM-MDN 的均值计算公式为 μ = μ_base + μ_offset，这主要是因为我们旨在验证 DM-MDN 能否准确感知并预测当前网络的负载状态。
由于网络环境的高度随机性，所有四种方法的预测精度整体偏低。然而，混合密度网络能够有效捕捉训练数据中的多峰分布特征，从而更准确地识别网络的当前负载情况，并基于负载状态在合理范围内作出预测。从表 1 数据可以看出，DM-MDN 在预测精度方面较基线模型 GRU 和 Transformer 分别提升了约 xx% 和 xx%，展现了其在复杂网络环境下的优越性能。此外，DM-MDN 与 MDN 在预测精度上差异极小，这证明了将均值进行结构化分解并不会损害模型的整体预测能力。

###### 预测模型在仿真中的结果
我们在三种不同负载场景下，对比了DM-MDN与基线方法在实际网络仿真中的性能表现。表2、表3和表4分别展示了数据包平均时延、丢包率和吞吐量的对比结果。

xxxx（具体表现）

在低负载场景下，我们发现基于GRU和Transformer的预测方法和DM-MDN相比出现较大的差异。通过分析在网络中GRU和Transformer的预测值发现，它们无法捕捉到当前是低负载的场景，其输出的预测值依然集中在高负载场景下的信道空闲情况。这导致了GRU和Transformer的预测值较小，而当节点数据包到达时，数据包到达的时隙很难落在预测的信道空闲时隙，这导致了节点数据包经常错过了发送时机。


##### LLM-Agent 实验结果
我们对比了本文提出的LLM Agent资源分配框架与Reflexion、Strategy以及传统贪心算法在四种大语言模型上的性能表现以及它们的资源占用情况。
###### 动态场景
为全面评估本文提出的LLM Agent资源分配框架性能，我们构建了一个具有动态优先级特性的无线网络实验场景。该场景由五个普通节点和一个接入点(AP)组成，网络中每个节点的数据包优先级均呈现动态变化特性。数据包优先级分为三个等级：优先级1（最低）、优先级2（中等）和优先级3（最高），其中优先级1的数据包不受传输时限限制，而优先级2和优先级3的数据包则分别设置了1200微秒和900微秒的截止时限(deadline)约束。
在实验过程中，每个节点的数据包优先级由均匀分布的随机算法确定，模拟实际网络中业务需求的变化特性。当节点数据包优先级发生变化后，系统会将网络中所有节点的最新优先级信息提交至资源分配算法。该算法根据当前网络状态和各节点需求，决定每个节点应采用的信道接入策略（传统CSMA/CA或基于DM-MDN的预测方法），并为选择DM-MDN策略的节点确定最优分位数参数，从而实现对异构节点的差异化资源分配与管理。
考虑到本研究主要针对动态实时网络环境，我们将高优先级节点的丢包率作为主要评估指标。在具有严格时限要求的场景中，数据包的可靠传输对保障服务质量至关重要，特别是对优先级较高的业务而言，丢包率能够直接反映算法在异构资源需求管理方面的能力。基于这一考虑，我们在LLM Agent的设计中将降低高优先级数据包的丢包率设定为优化的核心目标，以验证所提出框架在动态环境下的适应性和决策能力。
###### LLM-Agent 实验结果分析

###### 算法资源开销分析